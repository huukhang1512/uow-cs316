{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Author:\n",
    "\n",
    "- Huu Khang Nguyen - 7402909\n",
    "- hkn878@uowmail.edu.au\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Environment:\n",
    "\n",
    "- Python 3.10.8\n",
    "- Ubuntu 22.04.2 LTS x86_64\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Task:\n",
    "\n",
    "- Create 3 Decision Tree (DT) models to predict the application ranking with the following split criterias respectively:\n",
    "  - Information Gain\n",
    "  - Gain Ratio\n",
    "  - Gini Index (Gini impurity)\n",
    "- Afterward, build a random forest classifier from created 3 DT models\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('./data/nursery.data', names=[\n",
    "    'parents',\n",
    "    'has_nurs',\n",
    "    'form',\n",
    "    'children',\n",
    "    'housing',\n",
    "    'finance',\n",
    "    'social',\n",
    "    'health',\n",
    "    'application ranking'\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>parents</th>\n",
       "      <th>has_nurs</th>\n",
       "      <th>form</th>\n",
       "      <th>children</th>\n",
       "      <th>housing</th>\n",
       "      <th>finance</th>\n",
       "      <th>social</th>\n",
       "      <th>health</th>\n",
       "      <th>application ranking</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>usual</td>\n",
       "      <td>proper</td>\n",
       "      <td>complete</td>\n",
       "      <td>1</td>\n",
       "      <td>convenient</td>\n",
       "      <td>convenient</td>\n",
       "      <td>nonprob</td>\n",
       "      <td>recommended</td>\n",
       "      <td>recommend</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>usual</td>\n",
       "      <td>proper</td>\n",
       "      <td>complete</td>\n",
       "      <td>1</td>\n",
       "      <td>convenient</td>\n",
       "      <td>convenient</td>\n",
       "      <td>nonprob</td>\n",
       "      <td>priority</td>\n",
       "      <td>priority</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>usual</td>\n",
       "      <td>proper</td>\n",
       "      <td>complete</td>\n",
       "      <td>1</td>\n",
       "      <td>convenient</td>\n",
       "      <td>convenient</td>\n",
       "      <td>nonprob</td>\n",
       "      <td>not_recom</td>\n",
       "      <td>not_recom</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>usual</td>\n",
       "      <td>proper</td>\n",
       "      <td>complete</td>\n",
       "      <td>1</td>\n",
       "      <td>convenient</td>\n",
       "      <td>convenient</td>\n",
       "      <td>slightly_prob</td>\n",
       "      <td>recommended</td>\n",
       "      <td>recommend</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>usual</td>\n",
       "      <td>proper</td>\n",
       "      <td>complete</td>\n",
       "      <td>1</td>\n",
       "      <td>convenient</td>\n",
       "      <td>convenient</td>\n",
       "      <td>slightly_prob</td>\n",
       "      <td>priority</td>\n",
       "      <td>priority</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  parents has_nurs      form children     housing     finance         social   \n",
       "0   usual   proper  complete        1  convenient  convenient        nonprob  \\\n",
       "1   usual   proper  complete        1  convenient  convenient        nonprob   \n",
       "2   usual   proper  complete        1  convenient  convenient        nonprob   \n",
       "3   usual   proper  complete        1  convenient  convenient  slightly_prob   \n",
       "4   usual   proper  complete        1  convenient  convenient  slightly_prob   \n",
       "\n",
       "        health application ranking  \n",
       "0  recommended           recommend  \n",
       "1     priority            priority  \n",
       "2    not_recom           not_recom  \n",
       "3  recommended           recommend  \n",
       "4     priority            priority  "
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(12960, 9)"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Preprocessing the data\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Droping rows with NA values (if any)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>parents</th>\n",
       "      <th>has_nurs</th>\n",
       "      <th>form</th>\n",
       "      <th>children</th>\n",
       "      <th>housing</th>\n",
       "      <th>finance</th>\n",
       "      <th>social</th>\n",
       "      <th>health</th>\n",
       "      <th>application ranking</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>usual</td>\n",
       "      <td>proper</td>\n",
       "      <td>complete</td>\n",
       "      <td>1</td>\n",
       "      <td>convenient</td>\n",
       "      <td>convenient</td>\n",
       "      <td>nonprob</td>\n",
       "      <td>recommended</td>\n",
       "      <td>recommend</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>usual</td>\n",
       "      <td>proper</td>\n",
       "      <td>complete</td>\n",
       "      <td>1</td>\n",
       "      <td>convenient</td>\n",
       "      <td>convenient</td>\n",
       "      <td>nonprob</td>\n",
       "      <td>priority</td>\n",
       "      <td>priority</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>usual</td>\n",
       "      <td>proper</td>\n",
       "      <td>complete</td>\n",
       "      <td>1</td>\n",
       "      <td>convenient</td>\n",
       "      <td>convenient</td>\n",
       "      <td>nonprob</td>\n",
       "      <td>not_recom</td>\n",
       "      <td>not_recom</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>usual</td>\n",
       "      <td>proper</td>\n",
       "      <td>complete</td>\n",
       "      <td>1</td>\n",
       "      <td>convenient</td>\n",
       "      <td>convenient</td>\n",
       "      <td>slightly_prob</td>\n",
       "      <td>recommended</td>\n",
       "      <td>recommend</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>usual</td>\n",
       "      <td>proper</td>\n",
       "      <td>complete</td>\n",
       "      <td>1</td>\n",
       "      <td>convenient</td>\n",
       "      <td>convenient</td>\n",
       "      <td>slightly_prob</td>\n",
       "      <td>priority</td>\n",
       "      <td>priority</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12955</th>\n",
       "      <td>great_pret</td>\n",
       "      <td>very_crit</td>\n",
       "      <td>foster</td>\n",
       "      <td>more</td>\n",
       "      <td>critical</td>\n",
       "      <td>inconv</td>\n",
       "      <td>slightly_prob</td>\n",
       "      <td>priority</td>\n",
       "      <td>spec_prior</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12956</th>\n",
       "      <td>great_pret</td>\n",
       "      <td>very_crit</td>\n",
       "      <td>foster</td>\n",
       "      <td>more</td>\n",
       "      <td>critical</td>\n",
       "      <td>inconv</td>\n",
       "      <td>slightly_prob</td>\n",
       "      <td>not_recom</td>\n",
       "      <td>not_recom</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12957</th>\n",
       "      <td>great_pret</td>\n",
       "      <td>very_crit</td>\n",
       "      <td>foster</td>\n",
       "      <td>more</td>\n",
       "      <td>critical</td>\n",
       "      <td>inconv</td>\n",
       "      <td>problematic</td>\n",
       "      <td>recommended</td>\n",
       "      <td>spec_prior</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12958</th>\n",
       "      <td>great_pret</td>\n",
       "      <td>very_crit</td>\n",
       "      <td>foster</td>\n",
       "      <td>more</td>\n",
       "      <td>critical</td>\n",
       "      <td>inconv</td>\n",
       "      <td>problematic</td>\n",
       "      <td>priority</td>\n",
       "      <td>spec_prior</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12959</th>\n",
       "      <td>great_pret</td>\n",
       "      <td>very_crit</td>\n",
       "      <td>foster</td>\n",
       "      <td>more</td>\n",
       "      <td>critical</td>\n",
       "      <td>inconv</td>\n",
       "      <td>problematic</td>\n",
       "      <td>not_recom</td>\n",
       "      <td>not_recom</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>12960 rows × 9 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "          parents   has_nurs      form children     housing     finance   \n",
       "0           usual     proper  complete        1  convenient  convenient  \\\n",
       "1           usual     proper  complete        1  convenient  convenient   \n",
       "2           usual     proper  complete        1  convenient  convenient   \n",
       "3           usual     proper  complete        1  convenient  convenient   \n",
       "4           usual     proper  complete        1  convenient  convenient   \n",
       "...           ...        ...       ...      ...         ...         ...   \n",
       "12955  great_pret  very_crit    foster     more    critical      inconv   \n",
       "12956  great_pret  very_crit    foster     more    critical      inconv   \n",
       "12957  great_pret  very_crit    foster     more    critical      inconv   \n",
       "12958  great_pret  very_crit    foster     more    critical      inconv   \n",
       "12959  great_pret  very_crit    foster     more    critical      inconv   \n",
       "\n",
       "              social       health application ranking  \n",
       "0            nonprob  recommended           recommend  \n",
       "1            nonprob     priority            priority  \n",
       "2            nonprob    not_recom           not_recom  \n",
       "3      slightly_prob  recommended           recommend  \n",
       "4      slightly_prob     priority            priority  \n",
       "...              ...          ...                 ...  \n",
       "12955  slightly_prob     priority          spec_prior  \n",
       "12956  slightly_prob    not_recom           not_recom  \n",
       "12957    problematic  recommended          spec_prior  \n",
       "12958    problematic     priority          spec_prior  \n",
       "12959    problematic    not_recom           not_recom  \n",
       "\n",
       "[12960 rows x 9 columns]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.dropna()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Splitting the dataset\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "TRAINING_SPLIT = 0.6 # 60%\n",
    "shuffle_df = df.sample(frac=1)\n",
    "\n",
    "train_size = int(TRAINING_SPLIT * len(df))\n",
    "\n",
    "y = shuffle_df['application ranking']\n",
    "X = shuffle_df.drop(columns=['application ranking'])\n",
    "\n",
    "X_train = X[:train_size]\n",
    "y_train = y[:train_size]\n",
    "X_test = X[train_size:]\n",
    "y_test = y[train_size:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "5184"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(X_test)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Implementing the Decision Tree model\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "I will implement the decision tree model with the following properties:\n",
    "- **Binary split** decision tree\n",
    "- Early stopping critrias to improve training speed & prevent overfitting:\n",
    "    - When all records in the sample share the same class label (or number of unique class label equals 1)\n",
    "    - Minimum sample split: stop the splitting if the node contains fewer samples than this minimum\n",
    "    - Max depth of the tree: restrict the height of the tree\n",
    "    \n",
    "    *The node with the most common class label will be return when early stopping occured (base case)*"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Overall, when fitting the dataset into the decision tree, we will:\n",
    "- Recursively generating the decision tree by getting the most important feature to split the data. \n",
    "    - This is done by calculating the best splitting criterion (which can be information gain, gini index, or gain ratio, depending on what user chose as criterion for the classifier) for each feature.\n",
    "- Divide the data based on the selected splitting feature into two subsets.\n",
    "- The process will then be repeated for each subset until stopping criteria (as defined above) is reached. A leaf node will be added into the tree, with its `value` as the most common label across all the samples in that node"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "When predict a dataset with decision tree, the tree is traversed from the root node to leaf node (result label) base on the input features"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To make our decision tree reusable, I will use OOP for implementing the tree. Comments will be included in the code to explain integral part of the algorithm"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Node class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Node:\n",
    "    def __init__(\n",
    "        self,\n",
    "        feature=None,\n",
    "        threshold=None,\n",
    "        left=None,\n",
    "        right=None,\n",
    "        value=None,\n",
    "    ):\n",
    "        self.feature = feature\n",
    "        self.threshold = threshold\n",
    "        self.left = left\n",
    "        self.right = right\n",
    "        self.value = value\n",
    "\n",
    "    def is_leaf(self):\n",
    "        return self.value is not None # node contains the prediction (or in this case, the most common label)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Decision Tree class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections import Counter\n",
    "\n",
    "\n",
    "class DecisionTree:\n",
    "    def __init__(self, min_samples_split=2, max_depth=10, criterion='information_gain'):\n",
    "        self.min_samples_split = min_samples_split\n",
    "        self.max_depth = max_depth\n",
    "        self.criterion = criterion\n",
    "        self.root = None\n",
    "\n",
    "    # splitting criteria scoring functions\n",
    "    @staticmethod\n",
    "    def _shannon_entropy(y):\n",
    "        num_entries = len(y)\n",
    "        label_counts = Counter(y)\n",
    "        shannon_ent = 0.0\n",
    "\n",
    "        for label in label_counts:\n",
    "            prob = float(label_counts[label]) / num_entries\n",
    "            shannon_ent -= prob * np.log2(prob)\n",
    "        return shannon_ent\n",
    "\n",
    "    def _information_gain(self, y, left_sub_tree, right_sub_tree):\n",
    "        base_entropy = self._shannon_entropy(y)\n",
    "\n",
    "        num_entries = len(y)\n",
    "        num_left_entries = len(left_sub_tree)\n",
    "        num_right_entries = len(right_sub_tree)\n",
    "\n",
    "        left_entropy = self._shannon_entropy(y.iloc[left_sub_tree])\n",
    "        right_entropy = self._shannon_entropy(y.iloc[right_sub_tree])\n",
    "\n",
    "        child_entropy = (num_left_entries/num_entries) * left_entropy + \\\n",
    "            (num_right_entries/num_entries) * right_entropy\n",
    "\n",
    "        return base_entropy - child_entropy\n",
    "\n",
    "    @staticmethod\n",
    "    def _gini(y):\n",
    "        gini_index = 1\n",
    "        label_occurences = Counter(y)\n",
    "        total = len(y)\n",
    "\n",
    "        for label in label_occurences:\n",
    "            p = label_occurences[label]/total\n",
    "            gini_index -= np.square(p)\n",
    "\n",
    "        return gini_index\n",
    "\n",
    "    def _gini_index(self, y, left_sub_tree, right_sub_tree):\n",
    "        num_entries = len(y)\n",
    "        num_left_entries = len(left_sub_tree)\n",
    "        num_right_entries = len(right_sub_tree)\n",
    "\n",
    "        left_gini = self._gini(y.iloc[left_sub_tree])\n",
    "        right_gini = self._gini(y.iloc[right_sub_tree])\n",
    "        return (num_left_entries/num_entries) * left_gini + \\\n",
    "            (num_right_entries/num_entries) * right_gini\n",
    "\n",
    "    def _gain_ratio(self, y, left_sub_tree, right_sub_tree):\n",
    "        intrinsic_value = 0\n",
    "\n",
    "        num_entries = len(y)\n",
    "        num_left_entries = len(left_sub_tree)\n",
    "        num_right_entries = len(right_sub_tree)\n",
    "\n",
    "        for n in [num_left_entries, num_right_entries]:\n",
    "            if n > 0:\n",
    "                proportion = n/num_entries\n",
    "                intrinsic_value -= proportion * np.log2(proportion)\n",
    "\n",
    "        if intrinsic_value == 0:\n",
    "            return 0\n",
    "        return self._information_gain(y, left_sub_tree, right_sub_tree) / intrinsic_value\n",
    "\n",
    "    def _calculate_criteria(self, X, y, threshold):\n",
    "        # Split the tree first base on the current threshold\n",
    "        left_sub_tree, right_sub_tree = self._split(X, threshold)\n",
    "\n",
    "        match self.criterion:\n",
    "            case 'gini':\n",
    "                return self._gini_index(y, left_sub_tree, right_sub_tree)\n",
    "            case 'gain_ratio':\n",
    "                return self._gain_ratio(y, left_sub_tree, right_sub_tree)\n",
    "            case 'information_gain':\n",
    "                return self._information_gain(y, left_sub_tree, right_sub_tree)\n",
    "\n",
    "    # Function to build the tree recursively\n",
    "    def _generate_tree(self, X, y, cur_depth=0):\n",
    "        n_samples, n_features = X.shape\n",
    "        n_labels = len(np.unique(y))\n",
    " \n",
    "        # edge case, where there's no label in y\n",
    "        if(len(y) == 0):\n",
    "            return Node(value=None)\n",
    "            \n",
    "        # Early stopping \n",
    "        if (\n",
    "            cur_depth >= self.max_depth or \n",
    "            n_labels == 1 or\n",
    "            n_samples < self.min_samples_split\n",
    "        ):\n",
    "            most_common_label = Counter(y).most_common(1)[0][0]\n",
    "            return Node(value=most_common_label)\n",
    "\n",
    "        # Creating a random group for each recursive tree splitting\n",
    "        random_feature = np.random.choice(\n",
    "            n_features, n_features, replace=False)\n",
    "\n",
    "        # Find best split from parent\n",
    "        best_split_idx, best_split_threshold = self._get_best_split(\n",
    "            X, y, random_feature)\n",
    "\n",
    "        # Recursively build the left subtree and right subtree\n",
    "        left_sub_tree, right_sub_tree = self._split(\n",
    "            X.iloc[:, best_split_idx], best_split_threshold)\n",
    "\n",
    "        left = self._generate_tree(\n",
    "            X.iloc[left_sub_tree, :], y.iloc[left_sub_tree], cur_depth + 1)\n",
    "\n",
    "        right = self._generate_tree(\n",
    "            X.iloc[right_sub_tree, :], y.iloc[right_sub_tree], cur_depth + 1)\n",
    "\n",
    "        return Node(best_split_idx, best_split_threshold, left, right)\n",
    "\n",
    "    def _get_best_split(self, X, y, random_features):\n",
    "        max_criteria = float('-inf')\n",
    "        min_criteria = float('+inf')\n",
    "\n",
    "        best_split_idx = None\n",
    "        best_split_threshold = None\n",
    "        for feature_idx in random_features:\n",
    "            X_feature = X.iloc[:, feature_idx]\n",
    "            thresholds = np.unique(X_feature)\n",
    "\n",
    "            for threshold in thresholds:\n",
    "                # Calculate the criteria for splitting\n",
    "                criteria = self._calculate_criteria(X_feature, y, threshold)\n",
    "\n",
    "                # Updating the best split\n",
    "                # If gini index, the smaller the better\n",
    "                if (self.criterion == 'gini' and criteria < min_criteria):\n",
    "                    min_criteria = criteria\n",
    "                    best_split_idx = feature_idx\n",
    "                    best_split_threshold = threshold\n",
    "                    continue\n",
    "\n",
    "                # else if model used information gain and gain ratio criteria, the higher the better\n",
    "                if (criteria > max_criteria):\n",
    "                    max_criteria = criteria\n",
    "                    best_split_idx = feature_idx\n",
    "                    best_split_threshold = threshold\n",
    "\n",
    "        return best_split_idx, best_split_threshold\n",
    "\n",
    "    # Perform binary split the tree base on the given threshold ((A < v) or (A ≥ v))\n",
    "    def _split(self, X, threshold):\n",
    "        # group indices that are smaller than the split threshold\n",
    "        left_sub_tree = np.argwhere(X <= threshold).flatten()\n",
    "\n",
    "        # group indices that are larger than the threshold\n",
    "        right_sub_tree = np.argwhere(X > threshold).flatten()\n",
    "        return left_sub_tree, right_sub_tree\n",
    "\n",
    "    # Tree traversal function\n",
    "    def _dfs(self, x, node: Node):\n",
    "        if node.is_leaf():\n",
    "            return node.value\n",
    "        if x[node.feature] <= node.threshold:\n",
    "            return self._dfs(x, node.left)\n",
    "        return self._dfs(x, node.right)\n",
    "\n",
    "    def fit(self, X, y):\n",
    "        self.root = self._generate_tree(X, y)\n",
    "\n",
    "    def predict(self, X):\n",
    "        predictions = []\n",
    "        for _, x in X.iterrows():\n",
    "            predictions.append(self._dfs(x, self.root))\n",
    "\n",
    "        return np.array(predictions)\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Testing the decision tree models"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As a result, I implemented a reusuable decision tree that can be train with 3 different split criterias"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Decision tree using information gain"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "clf = DecisionTree(criterion='information_gain')\n",
    "clf.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = clf.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.9672067901234568\n"
     ]
    }
   ],
   "source": [
    "accuracy = np.sum(y_test == y_pred) / len(y_test)\n",
    "print(accuracy)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Decision tree using gini index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "clf = DecisionTree(criterion='gini')\n",
    "clf.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = clf.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.9488811728395061\n"
     ]
    }
   ],
   "source": [
    "accuracy = np.sum(y_test == y_pred) / len(y_test)\n",
    "print(accuracy)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Decision tree using gain ratio"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "clf = DecisionTree(criterion='gain_ratio')\n",
    "clf.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = clf.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.9660493827160493\n"
     ]
    }
   ],
   "source": [
    "accuracy = np.sum(y_test == y_pred) / len(y_test)\n",
    "print(accuracy)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Ensemble of the three to create random forrest"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "An ensemble method for decision trees also known as random forrest. Random forrest will utilise multiple decision tree (which making it a 'forrest'), and training each decision tree with random subset of data (hence 'random')"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For this Random Forrest model, I will compile 3 decision trees with different criterion. During prediction, all 3 decision tree will predict the input data. For each predicted value from each row, the most common prediction will be chose as the final prediction for that row"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "class RandomForrest:\n",
    "    def __init__(self, min_samples_split=2, max_depth=10):\n",
    "        self.min_samples_split = min_samples_split\n",
    "        self.max_depth = max_depth\n",
    "        self.trees = []\n",
    "\n",
    "    def fit(self, X, y):\n",
    "        criterions = ['gain_ratio', 'information_gain', 'gini']\n",
    "        for criteria in criterions:\n",
    "            tree = DecisionTree(\n",
    "                criterion=criteria,\n",
    "                min_samples_split=self.min_samples_split,\n",
    "                max_depth=self.max_depth\n",
    "            )\n",
    "            X_sample, y_sample = self._sample(X, y)\n",
    "            tree.fit(X_sample, y_sample)\n",
    "            self.trees.append(tree)\n",
    "\n",
    "    @staticmethod\n",
    "    def _sample(X, y):\n",
    "        n_rows, _ = X.shape\n",
    "        samples = np.random.choice(n_rows, n_rows, replace=True)\n",
    "        return X.iloc[samples], y.iloc[samples]\n",
    "\n",
    "    def predict(self, X):\n",
    "        preds = np.array([tree.predict(X) for tree in self.trees]) # get the predictions from all 3 trees\n",
    "        predictions = []\n",
    "        for row_num in range(X.shape[0]):\n",
    "            row_pred = [pred[row_num] for pred in preds]\n",
    "            predictions.append(Counter(row_pred).most_common(1)[0][0])\n",
    "        return np.array(predictions)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "random_forrest = RandomForrest()\n",
    "random_forrest.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = random_forrest.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.964891975308642\n"
     ]
    }
   ],
   "source": [
    "accuracy = np.sum(y_test == y_pred) / len(y_test)\n",
    "print(accuracy)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Overall, the random forrest model achieve a very good accuracy of ~96%. This could potentially improve by doing the following:\n",
    "- Hyperparameter tuning the classifier, where we can experiment with different variables until the desired accuracy is reached\n",
    "- Tree pruning, other than limiting the minimum sample size for each split, or limiting the tree height we can stop splitting current node if the entropy does not improve by some pre-defined preset (impurity threshold).\n",
    "    - For the implementation of this. I figure we can return the best criteria score in the `_get_best_split()` method in the decision tree. After that `_generate_tree()` will make an early stopping if the criteria score is below a certain threshold\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "a09b83e68d318d5f4a61abb5101d1b6410402f810fea7727edfcb8570048cbae"
  },
  "kernelspec": {
   "display_name": "Python 3.11.3 64-bit ('ass1-3QOYSfM0': pipenv)",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.3"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
